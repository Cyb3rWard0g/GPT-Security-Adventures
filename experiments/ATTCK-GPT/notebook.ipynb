{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ATT&CK GPT\n",
    "References:\n",
    "* https://python.langchain.com/en/latest/modules/indexes/getting_started.html"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create ATT&CK Groups Knowledge Base"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Modules and Define Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from attackcti import attack_client\n",
    "import os\n",
    "import logging\n",
    "\n",
    "logging.getLogger('taxii2client').setLevel(logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a few variables\n",
    "current_directory = os.path.dirname(\"__file__\")\n",
    "knowledge_directory = os.path.join(current_directory, \"knowledge\")\n",
    "db_directory = os.path.join(current_directory, \"db\")\n",
    "templates_directory = os.path.join(current_directory, \"templates\")\n",
    "group_template = os.path.join(templates_directory, \"group.md\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize ATT&CK Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lift = attack_client()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get ATT&CK Groups Knowledge\n",
    "Gettings technique STIX objects used by all groups accross all ATT&CK matrices.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'intrusion-set',\n",
       " 'id': 'intrusion-set--b7f627e2-0817-4cd5-8d50-e75f8aa85cc6',\n",
       " 'created_by_ref': 'identity--c78cb6e5-0c4b-4611-8297-d1b8b55e40b5',\n",
       " 'created': '2023-02-23T15:31:38.829Z',\n",
       " 'modified': '2023-04-17T21:49:16.371Z',\n",
       " 'name': 'LuminousMoth',\n",
       " 'description': '[LuminousMoth](https://attack.mitre.org/groups/G1014) is a Chinese-speaking cyber espionage group that has been active since at least October 2020. [LuminousMoth](https://attack.mitre.org/groups/G1014) has targeted high-profile organizations, including government entities, in Myanmar, the Philippines, Thailand, and other parts of Southeast Asia. Some security researchers have concluded there is a connection between [LuminousMoth](https://attack.mitre.org/groups/G1014) and [Mustang Panda](https://attack.mitre.org/groups/G0129) based on similar targeting and TTPs, as well as network infrastructure overlaps.(Citation: Kaspersky LuminousMoth July 2021)(Citation: Bitdefender LuminousMoth July 2021)',\n",
       " 'aliases': ['LuminousMoth'],\n",
       " 'external_references': [{'source_name': 'mitre-attack',\n",
       "   'url': 'https://attack.mitre.org/groups/G1014',\n",
       "   'external_id': 'G1014'},\n",
       "  {'source_name': 'Bitdefender LuminousMoth July 2021',\n",
       "   'description': 'Botezatu, B and etl. (2021, July 21). LuminousMoth - PlugX, File Exfiltration and Persistence Revisited. Retrieved October 20, 2022.',\n",
       "   'url': 'https://www.bitdefender.com/blog/labs/luminousmoth-plugx-file-exfiltration-and-persistence-revisited'},\n",
       "  {'source_name': 'Kaspersky LuminousMoth July 2021',\n",
       "   'description': 'Lechtik, M, and etl. (2021, July 14). LuminousMoth APT: Sweeping attacks for the chosen few. Retrieved October 20, 2022.',\n",
       "   'url': 'https://securelist.com/apt-luminousmoth/103332/'}],\n",
       " 'object_marking_refs': ['marking-definition--fa42a846-8d90-4e51-bc29-71d5b4802168'],\n",
       " 'x_mitre_attack_spec_version': '3.1.0',\n",
       " 'x_mitre_contributors': ['Kyaw Pyiyt Htet, @KyawPyiytHtet',\n",
       "  'Zaw Min Htun, @Z3TAE'],\n",
       " 'x_mitre_deprecated': False,\n",
       " 'x_mitre_domains': ['enterprise-attack'],\n",
       " 'x_mitre_modified_by_ref': 'identity--c78cb6e5-0c4b-4611-8297-d1b8b55e40b5',\n",
       " 'x_mitre_version': '1.0',\n",
       " 'technique_ref': 'attack-pattern--32901740-b42c-4fdd-bc02-345b5dc57082',\n",
       " 'relationship_description': '[LuminousMoth](https://attack.mitre.org/groups/G1014) has signed their malware with a valid digital signature.(Citation: Kaspersky LuminousMoth July 2021)',\n",
       " 'relationship_id': 'relationship--eb4ce173-6f0e-4c12-9ff8-09c4fb1ae2d3',\n",
       " 'revoked': False,\n",
       " 'technique': 'Code Signing',\n",
       " 'technique_description': 'Adversaries may create, acquire, or steal code signing materials to sign their malware or tools. Code signing provides a level of authenticity on a binary from the developer and a guarantee that the binary has not been tampered with. (Citation: Wikipedia Code Signing) The certificates used during an operation may be created, acquired, or stolen by the adversary. (Citation: Securelist Digital Certificates) (Citation: Symantec Digital Certificates) Unlike [Invalid Code Signature](https://attack.mitre.org/techniques/T1036/001), this activity will result in a valid signature.\\n\\nCode signing to verify software on first run can be used on modern Windows and macOS systems. It is not used on Linux due to the decentralized nature of the platform. (Citation: Wikipedia Code Signing)(Citation: EclecticLightChecksonEXECodeSigning)\\n\\nCode signing certificates may be used to bypass security policies that require signed code to execute on a system. ',\n",
       " 'tactic': [KillChainPhase(kill_chain_name='mitre-attack', phase_name='defense-evasion')],\n",
       " 'technique_id': 'T1553.002',\n",
       " 'matrix': 'mitre-attack',\n",
       " 'platform': ['macOS', 'Windows'],\n",
       " 'data_sources': ['File: File Metadata']}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "techniques_used_by_groups = lift.get_techniques_used_by_all_groups()\n",
    "techniques_used_by_groups[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create ATT&CK Groups Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Creating markadown files for each group..\n",
      "  [>>] Creating markdown file for LuminousMoth..\n",
      "  [>>] Creating markdown file for Metador..\n",
      "  [>>] Creating markdown file for CURIUM..\n",
      "  [>>] Creating markdown file for EXOTIC LILY..\n",
      "  [>>] Creating markdown file for Moses Staff..\n",
      "  [>>] Creating markdown file for SideCopy..\n",
      "  [>>] Creating markdown file for Aoqin Dragon..\n",
      "  [>>] Creating markdown file for Earth Lusca..\n",
      "  [>>] Creating markdown file for POLONIUM..\n",
      "  [>>] Creating markdown file for LAPSUS$..\n",
      "  [>>] Creating markdown file for Ember Bear..\n",
      "  [>>] Creating markdown file for BITTER..\n",
      "  [>>] Creating markdown file for Aquatic Panda..\n",
      "  [>>] Creating markdown file for Confucius..\n",
      "  [>>] Creating markdown file for LazyScripter..\n",
      "  [>>] Creating markdown file for TeamTNT..\n",
      "  [>>] Creating markdown file for Andariel..\n",
      "  [>>] Creating markdown file for Ferocious Kitten..\n",
      "  [>>] Creating markdown file for IndigoZebra..\n",
      "  [>>] Creating markdown file for BackdoorDiplomacy..\n",
      "  [>>] Creating markdown file for Transparent Tribe..\n",
      "  [>>] Creating markdown file for Nomadic Octopus..\n",
      "  [>>] Creating markdown file for Tonto Team..\n",
      "  [>>] Creating markdown file for Ajax Security Team..\n",
      "  [>>] Creating markdown file for Mustang Panda..\n",
      "  [>>] Creating markdown file for ZIRCONIUM..\n",
      "  [>>] Creating markdown file for TA551..\n",
      "  [>>] Creating markdown file for Higaisa..\n",
      "  [>>] Creating markdown file for HAFNIUM..\n",
      "  [>>] Creating markdown file for Windigo..\n",
      "  [>>] Creating markdown file for Volatile Cedar..\n",
      "  [>>] Creating markdown file for Silent Librarian..\n",
      "  [>>] Creating markdown file for Sidewinder..\n",
      "  [>>] Creating markdown file for Evilnum..\n",
      "  [>>] Creating markdown file for Indrik Spider..\n",
      "  [>>] Creating markdown file for Fox Kitten..\n",
      "  [>>] Creating markdown file for GOLD SOUTHFIELD..\n",
      "  [>>] Creating markdown file for Chimera..\n",
      "  [>>] Creating markdown file for Windshift..\n",
      "  [>>] Creating markdown file for Blue Mockingbird..\n",
      "  [>>] Creating markdown file for Whitefly..\n",
      "  [>>] Creating markdown file for Rocke..\n",
      "  [>>] Creating markdown file for DarkVishnya..\n",
      "  [>>] Creating markdown file for Mofang..\n",
      "  [>>] Creating markdown file for Wizard Spider..\n",
      "  [>>] Creating markdown file for Inception..\n",
      "  [>>] Creating markdown file for APT-C-36..\n",
      "  [>>] Creating markdown file for BlackTech..\n",
      "  [>>] Creating markdown file for APT41..\n",
      "  [>>] Creating markdown file for Machete..\n",
      "  [>>] Creating markdown file for Kimsuky..\n",
      "  [>>] Creating markdown file for GALLIUM..\n",
      "  [>>] Creating markdown file for TA505..\n",
      "  [>>] Creating markdown file for Silence..\n",
      "  [>>] Creating markdown file for WIRTE..\n",
      "  [>>] Creating markdown file for The White Company..\n",
      "  [>>] Creating markdown file for TEMP.Veles..\n",
      "  [>>] Creating markdown file for APT39..\n",
      "  [>>] Creating markdown file for FIN4..\n",
      "  [>>] Creating markdown file for Gallmaker..\n",
      "  [>>] Creating markdown file for SilverTerrier..\n",
      "  [>>] Creating markdown file for APT38..\n",
      "  [>>] Creating markdown file for Tropic Trooper..\n",
      "  [>>] Creating markdown file for Dark Caracal..\n",
      "  [>>] Creating markdown file for Gorgon Group..\n",
      "  [>>] Creating markdown file for Rancor..\n",
      "  [>>] Creating markdown file for Thrip..\n",
      "  [>>] Creating markdown file for Orangeworm..\n",
      "  [>>] Creating markdown file for HEXANE..\n",
      "  [>>] Creating markdown file for DarkHydrus..\n",
      "  [>>] Creating markdown file for Leafminer..\n",
      "  [>>] Creating markdown file for Cobalt Group..\n",
      "  [>>] Creating markdown file for APT19..\n",
      "  [>>] Creating markdown file for FIN8..\n",
      "  [>>] Creating markdown file for Elderwood..\n",
      "  [>>] Creating markdown file for BlackOasis..\n",
      "  [>>] Creating markdown file for MuddyWater..\n",
      "  [>>] Creating markdown file for Leviathan..\n",
      "  [>>] Creating markdown file for APT33..\n",
      "  [>>] Creating markdown file for APT37..\n",
      "  [>>] Creating markdown file for TA459..\n",
      "  [>>] Creating markdown file for PLATINUM..\n",
      "  [>>] Creating markdown file for Sowbug..\n",
      "  [>>] Creating markdown file for BRONZE BUTLER..\n",
      "  [>>] Creating markdown file for Magic Hound..\n",
      "  [>>] Creating markdown file for CopyKittens..\n",
      "  [>>] Creating markdown file for PROMETHIUM..\n",
      "  [>>] Creating markdown file for FIN5..\n",
      "  [>>] Creating markdown file for FIN10..\n",
      "  [>>] Creating markdown file for OilRig..\n",
      "  [>>] Creating markdown file for APT32..\n",
      "  [>>] Creating markdown file for RTM..\n",
      "  [>>] Creating markdown file for Gamaredon Group..\n",
      "  [>>] Creating markdown file for FIN7..\n",
      "  [>>] Creating markdown file for menuPass..\n",
      "  [>>] Creating markdown file for Winnti Group..\n",
      "  [>>] Creating markdown file for Group5..\n",
      "  [>>] Creating markdown file for Strider..\n",
      "  [>>] Creating markdown file for Patchwork..\n",
      "  [>>] Creating markdown file for Suckfly..\n",
      "  [>>] Creating markdown file for Stealth Falcon..\n",
      "  [>>] Creating markdown file for FIN6..\n",
      "  [>>] Creating markdown file for GCMAN..\n",
      "  [>>] Creating markdown file for Dragonfly..\n",
      "  [>>] Creating markdown file for Sandworm Team..\n",
      "  [>>] Creating markdown file for Poseidon Group..\n",
      "  [>>] Creating markdown file for Lazarus Group..\n",
      "  [>>] Creating markdown file for Scarlet Mimic..\n",
      "  [>>] Creating markdown file for Threat Group-1314..\n",
      "  [>>] Creating markdown file for Threat Group-3390..\n",
      "  [>>] Creating markdown file for APT18..\n",
      "  [>>] Creating markdown file for APT17..\n",
      "  [>>] Creating markdown file for Putter Panda..\n",
      "  [>>] Creating markdown file for APT16..\n",
      "  [>>] Creating markdown file for APT3..\n",
      "  [>>] Creating markdown file for Molerats..\n",
      "  [>>] Creating markdown file for Equation..\n",
      "  [>>] Creating markdown file for Naikon..\n",
      "  [>>] Creating markdown file for admin@338..\n",
      "  [>>] Creating markdown file for APT29..\n",
      "  [>>] Creating markdown file for APT30..\n",
      "  [>>] Creating markdown file for Darkhotel..\n",
      "  [>>] Creating markdown file for PittyTiger..\n",
      "  [>>] Creating markdown file for Turla..\n",
      "  [>>] Creating markdown file for Deep Panda..\n",
      "  [>>] Creating markdown file for Carbanak..\n",
      "  [>>] Creating markdown file for APT28..\n",
      "  [>>] Creating markdown file for APT1..\n",
      "  [>>] Creating markdown file for APT12..\n",
      "  [>>] Creating markdown file for Ke3chang..\n",
      "  [>>] Creating markdown file for Cleaver..\n",
      "  [>>] Creating markdown file for Moafee..\n",
      "  [>>] Creating markdown file for Axiom..\n",
      "  [>>] Creating markdown file for ALLANITE..\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "from jinja2 import Template\n",
    "\n",
    "# Create Group docs\n",
    "all_groups = dict()\n",
    "for technique in techniques_used_by_groups:\n",
    "    if technique['id'] not in all_groups:\n",
    "        group = dict()\n",
    "        group['group_name'] = technique['name']\n",
    "        group['group_id'] = technique['external_references'][0]['external_id']\n",
    "        group['created'] = technique['created']\n",
    "        group['modified'] = technique['modified']\n",
    "        group['description'] = technique['description']\n",
    "        group['aliases'] = technique['aliases']\n",
    "        if 'x_mitre_contributors' in technique:\n",
    "            group['contributors'] = technique['x_mitre_contributors']\n",
    "        group['techniques'] = []\n",
    "        all_groups[technique['id']] = group\n",
    "    technique_used = dict()\n",
    "    technique_used['matrix'] = technique['matrix']\n",
    "    technique_used['domain'] = technique['x_mitre_domains']\n",
    "    technique_used['platform'] = technique['platform']\n",
    "    technique_used['tactics'] = technique['tactic']\n",
    "    technique_used['technique_id'] = technique['technique_id']\n",
    "    technique_used['technique_name'] = technique['technique']\n",
    "    technique_used['use'] = technique['relationship_description']\n",
    "    if 'data_sources' in technique:\n",
    "        technique_used['data_sources'] = technique['data_sources']\n",
    "    all_groups[technique['id']]['techniques'].append(technique_used)\n",
    "\n",
    "if not os.path.exists(knowledge_directory):\n",
    "   print(\"[+] Creating knowledge directory..\")\n",
    "   os.makedirs(knowledge_directory)\n",
    "\n",
    "print(\"[+] Creating markadown files for each group..\")\n",
    "markdown_template = Template(open(group_template).read())\n",
    "for key in list(all_groups.keys()):\n",
    "    group = all_groups[key]\n",
    "    print(\"  [>>] Creating markdown file for {}..\".format(group['group_name']))\n",
    "    group_for_render = copy.deepcopy(group)\n",
    "    markdown = markdown_template.render(metadata=group_for_render, group_name=group['group_name'], group_id=group['group_id'])\n",
    "    file_name = (group['group_name']).replace(' ','_')\n",
    "    open(f'{knowledge_directory}/{file_name}.md', encoding='utf-8', mode='w').write(markdown)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Knowledge Base Embeddings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from langchain.document_loaders import UnstructuredMarkdownLoader\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Loading Group markdown files..\n",
      " [*] Loading admin@338.md\n",
      " [*] Loading Ajax_Security_Team.md\n",
      " [*] Loading ALLANITE.md\n",
      " [*] Loading Andariel.md\n",
      " [*] Loading Aoqin_Dragon.md\n",
      " [*] Loading APT-C-36.md\n",
      " [*] Loading APT1.md\n",
      " [*] Loading APT12.md\n",
      " [*] Loading APT16.md\n",
      " [*] Loading APT17.md\n",
      " [*] Loading APT18.md\n",
      " [*] Loading APT19.md\n",
      " [*] Loading APT28.md\n",
      " [*] Loading APT29.md\n",
      " [*] Loading APT3.md\n",
      " [*] Loading APT30.md\n",
      " [*] Loading APT32.md\n",
      " [*] Loading APT33.md\n",
      " [*] Loading APT37.md\n",
      " [*] Loading APT38.md\n",
      " [*] Loading APT39.md\n",
      " [*] Loading APT41.md\n",
      " [*] Loading Aquatic_Panda.md\n",
      " [*] Loading Axiom.md\n",
      " [*] Loading BackdoorDiplomacy.md\n",
      " [*] Loading BITTER.md\n",
      " [*] Loading BlackOasis.md\n",
      " [*] Loading BlackTech.md\n",
      " [*] Loading Blue_Mockingbird.md\n",
      " [*] Loading BRONZE_BUTLER.md\n",
      " [*] Loading Carbanak.md\n",
      " [*] Loading Chimera.md\n",
      " [*] Loading Cleaver.md\n",
      " [*] Loading Cobalt_Group.md\n",
      " [*] Loading Confucius.md\n",
      " [*] Loading CopyKittens.md\n",
      " [*] Loading CURIUM.md\n",
      " [*] Loading Darkhotel.md\n",
      " [*] Loading DarkHydrus.md\n",
      " [*] Loading DarkVishnya.md\n",
      " [*] Loading Dark_Caracal.md\n",
      " [*] Loading Deep_Panda.md\n",
      " [*] Loading Dragonfly.md\n",
      " [*] Loading Earth_Lusca.md\n",
      " [*] Loading Elderwood.md\n",
      " [*] Loading Ember_Bear.md\n",
      " [*] Loading Equation.md\n",
      " [*] Loading Evilnum.md\n",
      " [*] Loading EXOTIC_LILY.md\n",
      " [*] Loading Ferocious_Kitten.md\n",
      " [*] Loading FIN10.md\n",
      " [*] Loading FIN4.md\n",
      " [*] Loading FIN5.md\n",
      " [*] Loading FIN6.md\n",
      " [*] Loading FIN7.md\n",
      " [*] Loading FIN8.md\n",
      " [*] Loading Fox_Kitten.md\n",
      " [*] Loading GALLIUM.md\n",
      " [*] Loading Gallmaker.md\n",
      " [*] Loading Gamaredon_Group.md\n",
      " [*] Loading GCMAN.md\n",
      " [*] Loading GOLD_SOUTHFIELD.md\n",
      " [*] Loading Gorgon_Group.md\n",
      " [*] Loading Group5.md\n",
      " [*] Loading HAFNIUM.md\n",
      " [*] Loading HEXANE.md\n",
      " [*] Loading Higaisa.md\n",
      " [*] Loading Inception.md\n",
      " [*] Loading IndigoZebra.md\n",
      " [*] Loading Indrik_Spider.md\n",
      " [*] Loading Ke3chang.md\n",
      " [*] Loading Kimsuky.md\n",
      " [*] Loading LAPSUS$.md\n",
      " [*] Loading Lazarus_Group.md\n",
      " [*] Loading LazyScripter.md\n",
      " [*] Loading Leafminer.md\n",
      " [*] Loading Leviathan.md\n",
      " [*] Loading LuminousMoth.md\n",
      " [*] Loading Machete.md\n",
      " [*] Loading Magic_Hound.md\n",
      " [*] Loading menuPass.md\n",
      " [*] Loading Metador.md\n",
      " [*] Loading Moafee.md\n",
      " [*] Loading Mofang.md\n",
      " [*] Loading Molerats.md\n",
      " [*] Loading Moses_Staff.md\n",
      " [*] Loading MuddyWater.md\n",
      " [*] Loading Mustang_Panda.md\n",
      " [*] Loading Naikon.md\n",
      " [*] Loading Nomadic_Octopus.md\n",
      " [*] Loading OilRig.md\n",
      " [*] Loading Orangeworm.md\n",
      " [*] Loading Patchwork.md\n",
      " [*] Loading PittyTiger.md\n",
      " [*] Loading PLATINUM.md\n",
      " [*] Loading POLONIUM.md\n",
      " [*] Loading Poseidon_Group.md\n",
      " [*] Loading PROMETHIUM.md\n",
      " [*] Loading Putter_Panda.md\n",
      " [*] Loading Rancor.md\n",
      " [*] Loading Rocke.md\n",
      " [*] Loading RTM.md\n",
      " [*] Loading Sandworm_Team.md\n",
      " [*] Loading Scarlet_Mimic.md\n",
      " [*] Loading SideCopy.md\n",
      " [*] Loading Sidewinder.md\n",
      " [*] Loading Silence.md\n",
      " [*] Loading Silent_Librarian.md\n",
      " [*] Loading SilverTerrier.md\n",
      " [*] Loading Sowbug.md\n",
      " [*] Loading Stealth_Falcon.md\n",
      " [*] Loading Strider.md\n",
      " [*] Loading Suckfly.md\n",
      " [*] Loading TA459.md\n",
      " [*] Loading TA505.md\n",
      " [*] Loading TA551.md\n",
      " [*] Loading TeamTNT.md\n",
      " [*] Loading TEMP.Veles.md\n",
      " [*] Loading The_White_Company.md\n",
      " [*] Loading Threat_Group-1314.md\n",
      " [*] Loading Threat_Group-3390.md\n",
      " [*] Loading Thrip.md\n",
      " [*] Loading Tonto_Team.md\n",
      " [*] Loading Transparent_Tribe.md\n",
      " [*] Loading Tropic_Trooper.md\n",
      " [*] Loading Turla.md\n",
      " [*] Loading Volatile_Cedar.md\n",
      " [*] Loading Whitefly.md\n",
      " [*] Loading Windigo.md\n",
      " [*] Loading Windshift.md\n",
      " [*] Loading Winnti_Group.md\n",
      " [*] Loading WIRTE.md\n",
      " [*] Loading Wizard_Spider.md\n",
      " [*] Loading ZIRCONIUM.md\n",
      "[+] Number of .md documents processed: 134\n",
      "[+] Token Counts:\n",
      "Min: 176\n",
      "Avg: 1619\n",
      "Max: 7350\n"
     ]
    }
   ],
   "source": [
    "# variables\n",
    "group_files = glob.glob(os.path.join(knowledge_directory, \"*.md\"))\n",
    "\n",
    "# Loading Markdown files\n",
    "md_docs = []\n",
    "print(\"[+] Loading Group markdown files..\")\n",
    "for group in group_files:\n",
    "    print(f' [*] Loading {os.path.basename(group)}')\n",
    "    loader = UnstructuredMarkdownLoader(group)\n",
    "    md_docs.extend(loader.load())\n",
    "\n",
    "print(f'[+] Number of .md documents processed: {len(md_docs)}')\n",
    "\n",
    "tokenizer = tiktoken.get_encoding('cl100k_base')\n",
    "\n",
    "# create the length function\n",
    "def tiktoken_len(text):\n",
    "    tokens = tokenizer.encode(\n",
    "        text,\n",
    "        disallowed_special=()\n",
    "    )\n",
    "    return len(tokens)\n",
    "\n",
    "tiktoken.encoding_for_model('gpt-3.5-turbo')\n",
    "token_counts = [tiktoken_len(doc.page_content) for doc in md_docs]\n",
    "\n",
    "print(f\"\"\"[+] Token Counts:\n",
    "Min: {min(token_counts)}\n",
    "Avg: {int(sum(token_counts) / len(token_counts))}\n",
    "Max: {max(token_counts)}\"\"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.docstore.document import Document\n",
    "from tqdm.auto import tqdm\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Initializing RecursiveCharacterTextSplitter..\n",
      "[+] Splitting documents in chunks..\n",
      "[+] Number of chunks: 534\n"
     ]
    }
   ],
   "source": [
    "# Chunking Text\n",
    "print('[+] Initializing RecursiveCharacterTextSplitter..')\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=50,  # number of tokens overlap between chunks\n",
    "    length_function=tiktoken_len,\n",
    "    separators=['\\n\\n', '\\n', ' ', '']\n",
    ")\n",
    "\n",
    "print('[+] Splitting documents in chunks..')\n",
    "chunks = text_splitter.split_documents(md_docs)\n",
    "print(f'[+] Number of chunks: {len(chunks)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Splitting text in chunks..\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb383da3418145aea1267a6991159d16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/134 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Final Documents count: 534\n"
     ]
    }
   ],
   "source": [
    "print('[+] Splitting text in chunks..')\n",
    "json_documents = []\n",
    "chunks_documents = []\n",
    "m = hashlib.md5()\n",
    "for doc in tqdm(md_docs):\n",
    "    doc_name = os.path.basename(doc.metadata['source'])\n",
    "    m.update(doc_name.encode('utf-8'))\n",
    "    uid = m.hexdigest()[:12]\n",
    "    chunks = text_splitter.split_text(doc.page_content)\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        # Add JSON object to array\n",
    "        json_documents.append({\n",
    "            'id': f'{uid}-{i}',\n",
    "            'text': chunk,\n",
    "            'source': doc_name\n",
    "        })\n",
    "        # Create docs\n",
    "        document = Document(page_content=chunk, metadata={\"source\": doc_name})\n",
    "        chunks_documents.append(document)\n",
    "\n",
    "print(f'[+] Final Documents count: {len(json_documents)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export Knowledge Base as JSONL File (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Exporting groups as .jsonl file..\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(db_directory):\n",
    "   print('[+] Creating database directory..')\n",
    "   os.makedirs(db_directory)\n",
    "\n",
    "print(f'[+] Exporting groups as .jsonl file..')\n",
    "with open(f'{os.path.join(db_directory, \"attack-groups.jsonl\")}', 'w') as f:\n",
    "    for doc in json_documents:\n",
    "        f.write(json.dumps(doc) + '\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "current_directory = os.path.dirname(\"__file__\")\n",
    "db_directory = os.path.join(current_directory, \"db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get your key: https://platform.openai.com/account/api-keys\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_file = os.path.join(db_directory,\"db.pkl\")\n",
    "\n",
    "if not os.path.exists(db_file):\n",
    "    print(\"[+] Starting embedding..\")\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "\n",
    "    # Send text chunks to OpenAI Embeddings API\n",
    "    print(\"[+] Sending chunks to OpenAI Embeddings API..\")\n",
    "    db = FAISS.from_documents(chunks_documents, embeddings)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Database Pickle File (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "current_directory = os.path.dirname(\"__file__\")\n",
    "db_directory = os.path.join(current_directory, \"db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain.vectorstores.faiss.FAISS'>\n"
     ]
    }
   ],
   "source": [
    "db_file = os.path.join(db_directory,\"db.pkl\")\n",
    "\n",
    "if os.path.exists(db_file):\n",
    "    with open(db_file, \"rb\") as f:\n",
    "        db = pickle.load(f)\n",
    "else:\n",
    "    # Save vectorstore\n",
    "    print(\"[+] Create Pickle file..\")\n",
    "    with open(db_file, \"wb\") as f:\n",
    "        pickle.dump(db, f)\n",
    "\n",
    "print(type(db))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query ATT&CK Groups Knowledge Base"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize OpenAI (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "\n",
    "# Get your key: https://platform.openai.com/account/api-keys\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Vector Store Retriever\n",
    "The retriever interface is a generic interface that makes it easy to combine documents with language models. This interface exposes a get_relevant_documents method which takes in a query (a string) and returns a list of documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever(search_kwargs={\"k\":10})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Relevant Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What are some phishing techniques used by threat actors?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Getting relevant documents for query..\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(page_content='APT39 leveraged spearphishing emails with malicious attachments to initially compromise victims.(Citation: FireEye APT39 Jan 2019)(Citation: Symantec Chafer February 2018)(Citation: FBI FLASH APT39 September 2020)|', metadata={'source': 'APT39.md'}),\n",
       " Document(page_content='Lazarus Group has been observed targeting organizations using spearphishing documents with embedded malicious payloads. (Citation: Novetta Threat Research Group February 2016) Highly targeted spear phishing campaigns have been conducted against a U.S. electric grid company. (Citation: Eduard Kovacs March 2018)|', metadata={'source': 'Lazarus_Group.md'}),\n",
       " Document(page_content='TA505 has used spearphishing emails with malicious attachments to initially compromise victims.(Citation: Proofpoint TA505 Sep 2017)(Citation: Proofpoint TA505 June 2018)(Citation: Proofpoint TA505 Jan 2019)(Citation: Cybereason TA505 April 2019)(Citation: ProofPoint SettingContent-ms July 2018)(Citation: Proofpoint TA505 Mar 2018)(Citation: Trend Micro TA505 June 2019)(Citation: Proofpoint TA505 October 2019)(Citation: IBM TA505 April 2020)|', metadata={'source': 'TA505.md'}),\n",
       " Document(page_content='Nomadic Octopus has targeted victims with spearphishing emails containing malicious attachments.(Citation: Security Affairs DustSquad Oct 2018)(Citation: ESET Nomadic Octopus 2018)|', metadata={'source': 'Nomadic_Octopus.md'}),\n",
       " Document(page_content='APT29 has used spearphishing with a link to trick victims into clicking on a link to a zip file containing malicious files.(Citation: Mandiant No Easy Breach)(Citation: MSTIC NOBELIUM May 2021)(Citation: Secureworks IRON RITUAL USAID Phish May 2021)|\\n|mitre-attack|enterprise-attack|Linux,Windows,macOS|T1203|Exploitation for Client Execution|\\n\\nAPT29 has used multiple software exploits for common client software, like Microsoft Word, Exchange, and Adobe Reader, to gain code execution.(Citation: F-Secure The Dukes)(Citation: Cybersecurity Advisory SVR TTP May 2021)(Citation: MSTIC NOBELIUM May 2021)|\\n|mitre-attack|enterprise-attack|Linux,macOS,Windows,Network|T1090.003|Multi-hop Proxy|A backdoor used by\\n\\nAPT29 created a\\n\\nTor hidden service to forward traffic from the\\n\\nTor client to local ports 3389 (RDP), 139 (Netbios), and 445 (SMB) enabling full remote access from outside the network and has also used TOR.(Citation: Mandiant No Easy Breach)(Citation: MSTIC Nobelium Oct 2021)|\\n|mitre-attack|enterprise-attack|Linux,macOS,Windows|T1090.004|Domain Fronting|\\n\\nAPT29 has used the meek domain fronting plugin for\\n\\nTor to hide the destination of C2 traffic.(Citation: Mandiant No Easy Breach)|\\n|mitre-attack|enterprise-attack|macOS,Windows,Linux|T1027.002|Software Packing|\\n\\nAPT29 used UPX to pack files.(Citation: Mandiant No Easy Breach)|\\n|mitre-attack|enterprise-attack|Windows|T1550.003|Pass the Ticket|\\n\\nAPT29 used Kerberos ticket attacks for lateral movement.(Citation: Mandiant No Easy Breach)|\\n|mitre-attack|enterprise-attack|Windows|T1047|Windows Management Instrumentation|', metadata={'source': 'APT29.md'}),\n",
       " Document(page_content=\"APT33 utilize backdoors capable of capturing screenshots once installed on a system. (Citation: Jacqueline O'Leary et al. September 2017)(Citation: Junnosuke Yagi March 2017)|\\n|mitre-attack|enterprise-attack,ics-attack|Engineering Workstation,Human-Machine Interface,Control Server,Data Historian|T0865|Spearphishing Attachment|\\n\\nAPT33 sent spear phishing emails containing links to HTML application files, which were embedded with malicious code. (Citation: Jacqueline O'Leary et al. September 2017)\\n\\nAPT33 has conducted targeted spear phishing campaigns against U.S. government agencies and private sector companies. (Citation: Andy Greenburg June 2019)|\", metadata={'source': 'APT33.md'}),\n",
       " Document(page_content=\"Techniques Used\\n\\nAPT29 has used residential proxies, including Azure Virtual Machines, to obfuscate their access to victim environments.(Citation: Mandiant APT29 Microsoft 365 2022)|\\n|mitre-attack|enterprise-attack|Office 365,Windows,Google Workspace|T1114.002|Remote Email Collection|\\n\\nAPT29 has collected emails from targeted mailboxes within a compromised Azure AD tenant.(Citation: Mandiant APT29 Microsoft 365 2022)|\\n|mitre-attack|enterprise-attack|Windows,Office 365,Google Workspace|T1098.002|Additional Email Delegate Permissions|\\n\\nAPT29 has used a compromised global administrator account in Azure AD to backdoor a service principal with\\n\\nAPT29 has gained access to a global administrator account in Azure AD.(Citation: Mandiant APT29 Microsoft 365 2022)|\\n|mitre-attack|enterprise-attack|Windows,Azure AD,Office 365,SaaS,IaaS,Linux,macOS,Google Workspace,Containers,Network|T1078|Valid Accounts|\\n\\nAPT29 has used a compromised account to access an organization's VPN infrastructure.(Citation: Mandiant APT29 Microsoft 365 2022)|\\n|mitre-attack|enterprise-attack|Azure AD,Windows,SaaS|T1098.005|Device Registration|\\n\\nAPT29 has enrolled a device in MFA to an Azure AD environment following a successful password guessing attack against a dormant account.(Citation: Mandiant APT29 Microsoft 365 2022)|\\n|mitre-attack|enterprise-attack|Windows,Azure AD,Office 365,SaaS,IaaS,Linux,macOS,Google Workspace,Containers,Network|T1110.001|Password Guessing|\\n\\nAPT29 has successfully conducted password guessing attacks against a list of mailboxes.(Citation: Mandiant APT29 Microsoft 365 2022)|\\n|mitre-attack|enterprise-attack|Windows,macOS,Linux,Containers,IaaS|T1562.001|Disable or Modify Tools|\", metadata={'source': 'APT29.md'}),\n",
       " Document(page_content='APT29 has used various forms of spearphishing attempting to get a user to click on a malicous link.(Citation: MSTIC NOBELIUM May 2021)(Citation: Secureworks IRON RITUAL USAID Phish May 2021)|\\n|mitre-attack|enterprise-attack|Linux,macOS,Windows|T1105|Ingress Tool Transfer|\\n\\nAPT29 has downloaded additional tools and malware onto compromised networks.(Citation: Mandiant No Easy Breach)(Citation: PWC WellMess July 2020)(Citation: F-Secure The Dukes)|\\n|mitre-attack|enterprise-attack|PRE|T1587.001|Malware|\\n\\nAPT29 has used unique malware in many of their operations.(Citation: F-Secure The Dukes)(Citation: Mandiant No Easy Breach)(Citation: MSTIC Nobelium Toolset May 2021)|\\n|mitre-attack|enterprise-attack|Linux,macOS,Windows,Containers|T1036.005|Match Legitimate Name or Location|\\n\\nAPT29 has renamed malicious DLLs with legitimate names to appear benign; they have also created an Azure AD certificate with a Common Name that matched the display name of the compromised service principal.(Citation: SentinelOne NobleBaron June 2021)(Citation: Mandiant APT29 Microsoft 365 2022)|\\n|mitre-attack|enterprise-attack|Windows,Linux,Containers,macOS|T1133|External Remote Services|\\n\\nAPT29 has used compromised identities to access networks via VPNs and Citrix.(Citation: NCSC APT29 July 2020)(Citation: Mandiant APT29 Microsoft 365 2022)|\\n|mitre-attack|enterprise-attack|PRE|T1587.003|Digital Certificates|\\n\\nAPT29 has created self-signed digital certificates to enable mutual TLS authentication for malware.(Citation: PWC WellMess July 2020)(Citation: PWC WellMess C2 August 2020)|\\n|mitre-attack|enterprise-attack|PRE|T1583.006|Web Services|\\n\\nAPT29 has registered algorithmically generated Twitter handles that are used for C2 by malware, such as\\n\\nHAMMERTOSS.', metadata={'source': 'APT29.md'}),\n",
       " Document(page_content='Magic Hound has attempted to lure victims into opening malicious email attachments.(Citation: ClearSky Kittens Back 3 August 2020)|\\n|mitre-attack|enterprise-attack|PRE|T1585.001|Social Media Accounts|\\n\\nMagic Hound has created fake LinkedIn and other social media accounts to contact targets and convince them--through messages and voice communications--to open malicious links.(Citation: ClearSky Kittens Back 3 August 2020)|\\n|mitre-attack|enterprise-attack|PRE|T1584.001|Domains|\\n\\nMagic Hound has used compromised domains to host links targeted to specific phishing victims.(Citation: ClearSky Kittens Back 3 August 2020)(Citation: Proofpoint TA453 July2021)(Citation: Certfa Charming Kitten January 2021)(Citation: Google Iran Threats October 2021)|\\n|mitre-attack|enterprise-attack|PRE|T1583.001|Domains|\\n\\nMagic Hound has registered fraudulent domains such as \"mail-newyorker.com\" and \"news12.com.recover-session-service.site\" to target specific victims with phishing attacks.(Citation: Certfa Charming Kitten January 2021)|\\n|mitre-attack|enterprise-attack|PRE|T1598.003|Spearphishing Link|\\n\\nMagic Hound has used SMS and email messages with links designed to steal credentials or track victims.(Citation: Certfa Charming Kitten January 2021)(Citation: ClearSky Kittens Back 3 August 2020)(Citation: Proofpoint TA453 March 2021)(Citation: Proofpoint TA453 July2021)(Citation: Google Iran Threats October 2021)(Citation: Microsoft Iranian Threat Actor Trends November 2021)|\\n|mitre-attack|enterprise-attack|Windows,Office 365,Google Workspace,macOS,Linux|T1114|Email Collection|\\n\\nMagic Hound has compromised email credentials in order to steal sensitive data.(Citation: Certfa Charming Kitten January 2021)|\\n|mitre-attack|enterprise-attack|PRE|T1586.002|Email Accounts|', metadata={'source': 'Magic_Hound.md'}),\n",
       " Document(page_content='TA551 has used spoofed company emails that were acquired from email clients on previously infected hosts to target other individuals.(Citation: Unit 42 TA551 Jan 2021)|\\n|mitre-attack|enterprise-attack|Linux,macOS,Windows|T1105|Ingress Tool Transfer|\\n\\nTA551 has retrieved DLLs and installer binaries for malware execution from C2.(Citation: Unit 42 TA551 Jan 2021)|\\n|mitre-attack|enterprise-attack|Linux,macOS,Windows|T1027.003|Steganography|\\n\\nTA551 has hidden encoded data for malware DLLs in a PNG.(Citation: Unit 42 TA551 Jan 2021)|\\n|mitre-attack|enterprise-attack|Linux,macOS,Windows|T1071.001|Web Protocols|\\n\\nTA551 has used HTTP for C2 communications.(Citation: Unit 42 Valak July 2020)|\\n|mitre-attack|enterprise-attack|Windows|T1218.011|Rundll32|\\n\\nTA551 has used rundll32.exe to load malicious DLLs.(Citation: Unit 42 TA551 Jan 2021)|\\n|mitre-attack|enterprise-attack|Windows|T1218.010|Regsvr32|\\n\\nTA551 has used regsvr32.exe to load malicious DLLs.(Citation: Unit 42 Valak July 2020)|\\n|mitre-attack|enterprise-attack|Linux,macOS,Windows|T1132.001|Standard Encoding|\\n\\nTA551 has used encoded ASCII text for initial C2 communications.(Citation: Unit 42 Valak July 2020)|\\n|mitre-attack|enterprise-attack|Linux,macOS,Windows,Containers|T1036|Masquerading|\\n\\nTA551 has masked malware DLLs as dat and jpg files.(Citation: Unit 42 TA551 Jan 2021)|\\n|mitre-attack|enterprise-attack|Linux,macOS,Windows|T1027.010|Command Obfuscation|\\n\\nTA551 has used obfuscated variable names in a JavaScript configuration file.(Citation: Unit 42 Valak July 2020)|', metadata={'source': 'TA551.md'})]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"[+] Getting relevant documents for query..\")\n",
    "relevant_docs = retriever.get_relevant_documents(query)\n",
    "relevant_docs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Threat actors have used spearphishing emails with malicious attachments, links to HTML application files embedded with malicious code, links to malicious zip files, and messages with links designed to steal credentials or track victims.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = load_qa_chain(OpenAI(temperature=0), chain_type=\"stuff\")\n",
    "chain.run(input_documents=relevant_docs, question=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
